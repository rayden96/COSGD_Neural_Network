{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  label  sex  smoker  day  time  size\n",
       "0       16.99   1.01  0.0     0.0  0.0   0.0     2\n",
       "1       10.34   1.66  0.0     0.0  0.0   0.0     3\n",
       "2       21.01   3.50  0.0     0.0  0.0   0.0     3\n",
       "3       23.68   3.31  0.0     0.0  0.0   0.0     2\n",
       "4       24.59   3.61  0.0     0.0  0.0   0.0     4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_or_create_dataset(filepath='dataset.csv', create_new=False, n_samples=1000, n_features=20):\n",
    "    if create_new:\n",
    "        data = np.random.rand(n_samples, n_features)\n",
    "        labels = np.random.randint(0, 2, n_samples)\n",
    "        dataset = pd.DataFrame(data)\n",
    "        dataset['label'] = labels\n",
    "        dataset.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        dataset = pd.read_csv(filepath)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Load or create the dataset\n",
    "dataset = load_or_create_dataset(create_new=False)\n",
    "dataset = dataset.apply(pd.to_numeric, errors='coerce')\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "#change the column name of the 'tip' column to 'label'\n",
    "label_name = 'tip'\n",
    "dataset.rename(columns={label_name:'label'}, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Phase:\n",
    "\n",
    "Cluster the dataset into different clusters\n",
    "TODO: identify 3-5 different clustering methods to use\n",
    "TODO: identify visualization and statistics relevant to the method to display (clustering index, cluster weight etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_dataset(dataset, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    features = dataset.drop('tip', axis=1).values\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "    dataset['cluster'] = clusters\n",
    "    \n",
    "    return dataset, clusters\n",
    "\n",
    "# Cluster the dataset\n",
    "n_clusters = 5\n",
    "dataset, clusters = cluster_dataset(dataset, n_clusters=n_clusters)\n",
    "dataset.head()\n",
    "\n",
    "#graph the clusters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='cluster', data=dataset)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Optimizer Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model architecture\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(CustomModel, self).__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(in_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_size = hidden_size\n",
    "        layers.append(nn.Linear(in_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "#Define the custom optimizer\n",
    "class COSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(COSGD, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                p.data.add_(-group['lr'], d_p)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Orthogonalize gradients using Gram-Schmidt process\n",
    "def gram_schmidt(gradients):\n",
    "    orthogonalized = []\n",
    "    for g in gradients:\n",
    "        w = g.clone()\n",
    "        for og in orthogonalized:\n",
    "            w -= torch.dot(w, og) * og\n",
    "        w /= torch.norm(w)\n",
    "        orthogonalized.append(w)\n",
    "    return orthogonalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop for the control model (standard)\n",
    "def train_model(model, optimizer, dataloader, loss_function, epochs=10):\n",
    "    criterion = loss_function\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "#prepare data loader for the control model\n",
    "features = dataset.drop(['label', 'cluster'], axis=1).values\n",
    "labels = dataset['label'].values\n",
    "tensor_data = TensorDataset(torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32))\n",
    "dataloader_control = DataLoader(tensor_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders for each cluster for the COSGD optimizer and name them as such\n",
    "dataloaders_cosgd = {}\n",
    "for cluster in np.unique(clusters):\n",
    "    cluster_data = dataset[dataset['cluster'] == cluster]\n",
    "    features = cluster_data.drop(['tip', 'cluster'], axis=1).values\n",
    "    labels = cluster_data['tip'].values\n",
    "    tensor_data = TensorDataset(torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32))\n",
    "    dataloaders_cosgd[cluster] = DataLoader(tensor_data, batch_size=32, shuffle=True)\n",
    "\n",
    "#create a function to train the model using COSGD\n",
    "def train_model_COSGD(model, dataloaders, loss_function, epochs=10):\n",
    "    criterion = loss_function\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        gradient_updates = []\n",
    "        for cluster, dataloader in dataloaders.items():\n",
    "            for inputs, labels in dataloader:\n",
    "                optimizer = COSGD(model.parameters())\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                gradients = [p.grad.data for p in model.parameters()]\n",
    "                gradient_updates.append(gradients)\n",
    "            \n",
    "        #we have our gradients\n",
    "        #todo sort the gradients on average absolute value descending\n",
    "        orthogonalized_gradients = gram_schmidt(gradient_updates)\n",
    "        #now we update the model with the orthogonalized gradients\n",
    "        #Todo write this code\n",
    "                \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architectures\n",
    "input_size = dataset.shape[1] - 2  # excluding label and cluster columns\n",
    "hidden_layers = [6]\n",
    "output_size = 1\n",
    "model_control = CustomModel(input_size, hidden_layers, output_size)\n",
    "model_cosgd = CustomModel(input_size, hidden_layers, output_size)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_control = optim.SGD(model_control.parameters(), lr=0.01)\n",
    "optimizer_cosgd = COSGD(model_cosgd.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "start_time_control = time.time()\n",
    "model_control = train_model(model_control, optimizer_control, dataloader_control, epochs=10)\n",
    "end_time_control = time.time()\n",
    "\n",
    "start_time_cosgd = time.time()\n",
    "model_cosgd = train_model_COSGD(model_cosgd, optimizer_cosgd, dataloader_cosgd, epochs=10)\n",
    "end_time_cosgd = time.time()\n",
    "\n",
    "# Print results\n",
    "print(f\"SGD Training Time: {end_time_sgd - start_time_sgd:.2f} seconds\")\n",
    "print(f\"COSGD Training Time: {end_time_cosgd - start_time_cosgd:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the models performance\n",
    "TODO - decide on metrics to use \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
